--- 
title: 'Modeling HCV Data - Classification Models'
author:
- <span style="color:#1E90FF">John Koomson</span>, FSA, MAAA

date: "November 2022"
output:
  html_document:
    df_print: paged
site: bookdown::bookdown_site
documentclass: book
bibliography:
- book.bib
- packages.bib
biblio-style: apalike
cover-image: 
link-citations: yes
description:
subtitle: null
---

# Models {-}

Placeholder



<!--chapter:end:index.Rmd-->


# Data Cleaning {#data}

Placeholder



<!--chapter:end:01-CleanData.Rmd-->


# Exploratory Data Analysis {#dataanalysis}

Placeholder


## FINDINGS

<!--chapter:end:02-EDA.Rmd-->


# LOGISTIC REGRESSION

Placeholder


## Data Partitioning
## 5-Fold Cross Validation - Logistic Regression
## Fitting the Best Model

<!--chapter:end:03-Logistic.Rmd-->

# FITTING RANDOM FOREST


```{r, include=FALSE}
library(randomForest)
```


```{r}
data<-read.csv("data/CleanedData.csv",header = T,colClasses=c("NULL", rep(NA, 13)))

set.seed(120)
V <- 5
n <- NROW(data); n0 <- sum(data$Category==0); n1 <- n-n0;

missclass.rate = c()
err_vec1=c()

for (v in 1:V) {
  err_vec1=c(err_vec1, v)
  missclass.rate=c(missclass.rate, v)
}
id.fold <- 1:n
id.fold[data$Category==0] <- sample(x=1:V, size=n0, replace=TRUE)
id.fold[data$Category==1] <- sample(x=1:V, size=n1, replace=TRUE)
for (v in 1:V) {
train.v <- data[id.fold!=v, ]; test.v <- data[id.fold==v, ];

mtry = tuneRF(train.v[ , -1], factor(train.v$Category), ntreeTry=200,
              stepFactor=2, improve=0.05, trace=TRUE, 
              plot=FALSE, dobest=FALSE, printFlag = FALSE)

best.mtry = mtry[mtry[, 2] == min(mtry[, 2]), 1]

## Fitting model for Random Forest.

fit.rf = randomForest(factor(Category) ~., mtry=best.mtry,
                      data=train.v, importance=TRUE, proximity=TRUE,
                      ntree=500)
yobs = test.v$Category
pred.rf = predict(fit.rf, newdata=test.v[, -1], type="prob")[, 2]
mod = roc.area(yobs, pred.rf)$A
err_vec1[v] = mod
print(paste("AUC for fold", v, ":", err_vec1[v]))

pred.rate = ifelse(pred.rf > 0.5, 1, 0)
miss.rate <- mean(yobs != pred.rate)
missclass.rate[v] = miss.rate
print(paste("Missclassification rate for fold", v,
           ":",missclass.rate[v]))
}
varImpPlot(fit.rf)    ##Variance Importance Plot
importance(fit.rf)  
```

**comment**
The importance ranking shows that.AST,ALP,ALT are the important variables by random forest respectively.


```{r}
Average.Auc.rf<-print(paste("Average of AUC is ", mean(err_vec1)))
Average.mis.rf<-print(paste("Average of Miss is ", mean(missclass.rate)))
AUC.RF<-mean(err_vec1)
miss.rate.RF<-mean(missclass.rate)
```
**comment**

The average AUC of the v folds is 0.98 which shows a good classification by the random forest leading to a low misclassification is 0.02.

<!--chapter:end:04-RandomForest.Rmd-->


# V-FOLDS FOR MULTIVARIATE ADAPTIVE REGRESSION SPLINES 

Placeholder



<!--chapter:end:05-MARS.Rmd-->

